{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode\n",
    "from urllib.request import urlopen\n",
    "import pickle\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SubmissionBase:\n",
    "\n",
    "    submit_url = 'https://www-origin.coursera.org/api/' \\\n",
    "                 'onDemandProgrammingImmediateFormSubmissions.v1'\n",
    "    save_file = 'token.pkl'\n",
    "\n",
    "    def __init__(self, assignment_slug, part_names):\n",
    "        self.assignment_slug = assignment_slug\n",
    "        self.part_names = part_names\n",
    "        self.login = None\n",
    "        self.token = None\n",
    "        self.functions = OrderedDict()\n",
    "        self.args = dict()\n",
    "\n",
    "    def grade(self):\n",
    "        print('\\nSubmitting Solutions | Programming Exercise %s\\n' % self.assignment_slug)\n",
    "        self.login_prompt()\n",
    "\n",
    "        # Evaluate the different parts of exercise\n",
    "        parts = OrderedDict()\n",
    "        for part_id, result in self:\n",
    "            parts[str(part_id)] = {'output': sprintf('%0.5f ', result)}\n",
    "        result, response = self.request(parts)\n",
    "        response = json.loads(response)\n",
    "\n",
    "        # if an error was returned, print it and stop\n",
    "        if 'errorMessage' in response:\n",
    "            print(response['errorMessage'])\n",
    "            return\n",
    "\n",
    "        # Print the grading table\n",
    "        print('%43s | %9s | %-s' % ('Part Name', 'Score', 'Feedback'))\n",
    "        print('%43s | %9s | %-s' % ('---------', '-----', '--------'))\n",
    "        for part in parts:\n",
    "            part_feedback = response['partFeedbacks'][part]\n",
    "            part_evaluation = response['partEvaluations'][part]\n",
    "            score = '%d / %3d' % (part_evaluation['score'], part_evaluation['maxScore'])\n",
    "            print('%43s | %9s | %-s' % (self.part_names[int(part) - 1], score, part_feedback))\n",
    "        evaluation = response['evaluation']\n",
    "        total_score = '%d / %d' % (evaluation['score'], evaluation['maxScore'])\n",
    "        print('                                  --------------------------------')\n",
    "        print('%43s | %9s | %-s\\n' % (' ', total_score, ' '))\n",
    "\n",
    "    def login_prompt(self):\n",
    "        if os.path.isfile(self.save_file):\n",
    "            with open(self.save_file, 'rb') as f:\n",
    "                login, token = pickle.load(f)\n",
    "            reenter = input('Use token from last successful submission (%s)? (Y/n): ' % login)\n",
    "\n",
    "            if reenter == '' or reenter[0] == 'Y' or reenter[0] == 'y':\n",
    "                self.login, self.token = login, token\n",
    "                return\n",
    "            else:\n",
    "                os.remove(self.save_file)\n",
    "\n",
    "        self.login = input('Login (email address): ')\n",
    "        self.token = input('Token: ')\n",
    "\n",
    "        # Save the entered credentials\n",
    "        if not os.path.isfile(self.save_file):\n",
    "            with open(self.save_file, 'wb') as f:\n",
    "                pickle.dump((self.login, self.token), f)\n",
    "\n",
    "    def request(self, parts):\n",
    "        params = {\n",
    "            'assignmentSlug': self.assignment_slug,\n",
    "            'secret': self.token,\n",
    "            'parts': parts,\n",
    "            'submitterEmail': self.login}\n",
    "\n",
    "        params = urlencode({'jsonBody': json.dumps(params)}).encode(\"utf-8\")\n",
    "        f = urlopen(self.submit_url, params)\n",
    "        try:\n",
    "            return 0, f.read()\n",
    "        finally:\n",
    "            f.close()\n",
    "\n",
    "    def __iter__(self):\n",
    "        for part_id in self.functions:\n",
    "            yield part_id\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        self.functions[key] = value\n",
    "\n",
    "\n",
    "def sprintf(fmt, arg):\n",
    "    \"\"\" Emulates (part of) Octave sprintf function. \"\"\"\n",
    "    if isinstance(arg, tuple):\n",
    "        # for multiple return values, only use the first one\n",
    "        arg = arg[0]\n",
    "\n",
    "    if isinstance(arg, (np.ndarray, list)):\n",
    "        # concatenates all elements, column by column\n",
    "        return ' '.join(fmt % e for e in np.asarray(arg).ravel('F'))\n",
    "    else:\n",
    "        return fmt % arg\n",
    "    \n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "\n",
    "\n",
    "class Grader(SubmissionBase):\n",
    "    X1 = np.column_stack((np.ones(20), np.exp(1) + np.exp(2) * np.linspace(0.1, 2, 20)))\n",
    "    Y1 = X1[:, 1] + np.sin(X1[:, 0]) + np.cos(X1[:, 1])\n",
    "    X2 = np.column_stack((X1, X1[:, 1]**0.5, X1[:, 1]**0.25))\n",
    "    Y2 = np.power(Y1, 0.5) + Y1\n",
    "\n",
    "    def __init__(self):\n",
    "        part_names = ['Warm up exercise',\n",
    "                      'Computing Cost (for one variable)',\n",
    "                      'Gradient Descent (for one variable)',\n",
    "                      'Feature Normalization',\n",
    "                      'Computing Cost (for multiple variables)',\n",
    "                      'Gradient Descent (for multiple variables)',\n",
    "                      'Normal Equations']\n",
    "        super().__init__('linear-regression', part_names)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for part_id in range(1, 8):\n",
    "            try:\n",
    "                func = self.functions[part_id]\n",
    "\n",
    "                # Each part has different expected arguments/different function\n",
    "                if part_id == 1:\n",
    "                    res = func()\n",
    "                elif part_id == 2:\n",
    "                    res = func(self.X1, self.Y1, np.array([0.5, -0.5]))\n",
    "                elif part_id == 3:\n",
    "                    res = func(self.X1, self.Y1, np.array([0.5, -0.5]), 0.01, 10)\n",
    "                elif part_id == 4:\n",
    "                    res = func(self.X2[:, 1:4])\n",
    "                elif part_id == 5:\n",
    "                    res = func(self.X2, self.Y2, np.array([0.1, 0.2, 0.3, 0.4]))\n",
    "                elif part_id == 6:\n",
    "                    res = func(self.X2, self.Y2, np.array([-0.1, -0.2, -0.3, -0.4]), 0.01, 10)\n",
    "                elif part_id == 7:\n",
    "                    res = func(self.X2, self.Y2)\n",
    "                else:\n",
    "                    raise KeyError\n",
    "                yield part_id, res\n",
    "            except KeyError:\n",
    "                yield part_id, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # needed to plot 3-D surfaces\n",
    "\n",
    "# library written for this exercise providing additional functions for assignment submission, and others\n",
    "\n",
    "\n",
    "# define the submission/grader object for this exercise\n",
    "grader = Grader()\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.eye(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def warmUpExercise():\n",
    "    \"\"\"\n",
    "    Example function in Python which computes the identity matrix.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A : array_like\n",
    "        The 5x5 identity matrix.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Return the 5x5 identity matrix.\n",
    "    \"\"\"    \n",
    "    # ======== YOUR CODE HERE ======\n",
    "    A = np.eye(5)  # modify this line\n",
    "    \n",
    "    # ==============================\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warmUpExercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.592  ,  9.1302 , 13.662  , 11.854  ,  6.8233 , 11.886  ,\n",
       "        4.3483 , 12.     ,  6.5987 ,  3.8166 ,  3.2522 , 15.505  ,\n",
       "        3.1551 ,  7.2258 ,  0.71618,  3.5129 ,  5.3048 ,  0.56077,\n",
       "        3.6518 ,  5.3893 ,  3.1386 , 21.767  ,  4.263  ,  5.1875 ,\n",
       "        3.0825 , 22.638  , 13.501  ,  7.0467 , 14.692  , 24.147  ,\n",
       "       -1.22   ,  5.9966 , 12.134  ,  1.8495 ,  6.5426 ,  4.5623 ,\n",
       "        4.1164 ,  3.3928 , 10.117  ,  5.4974 ,  0.55657,  3.9115 ,\n",
       "        5.3854 ,  2.4406 ,  6.7318 ,  1.0463 ,  5.1337 ,  1.844  ,\n",
       "        8.0043 ,  1.0179 ,  6.7504 ,  1.8396 ,  4.2885 ,  4.9981 ,\n",
       "        1.4233 , -1.4211 ,  2.4756 ,  4.6042 ,  3.9624 ,  5.4141 ,\n",
       "        5.1694 , -0.74279, 17.929  , 12.054  , 17.054  ,  4.8852 ,\n",
       "        5.7442 ,  7.7754 ,  1.0173 , 20.992  ,  6.6799 ,  4.0259 ,\n",
       "        1.2784 ,  3.3411 , -2.6807 ,  0.29678,  3.8845 ,  5.7014 ,\n",
       "        6.7526 ,  2.0576 ,  0.47953,  0.20421,  0.67861,  7.5435 ,\n",
       "        5.3436 ,  4.2415 ,  6.7981 ,  0.92695,  0.152  ,  2.8214 ,\n",
       "        1.8451 ,  4.2959 ,  7.2029 ,  1.9869 ,  0.14454,  9.0551 ,\n",
       "        0.61705])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part 2 Linear Regression with One Variable\n",
    "data = np.loadtxt(os.path.join('Data', 'ex1data1.txt'), delimiter=',')\n",
    "x, y = data[:, 0], data[:, 1]\n",
    "m = y.size  # number of training examples\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(x,y):\n",
    "    fig = pyplot.figure()\n",
    "    pyplot.plot(x,y,'ro',ms=10,mec='k') #Plots X vs. Y\n",
    "    pyplot.ylabel('profit in $10,000')\n",
    "    pyplot.xlabel('Population of City')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotData(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Descent\n",
    "#We have to add another dimension to the data. We add theta(0) \n",
    "#To add another column to an array/data table:\n",
    "x = np.stack([np.ones(m), x], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(x, y, theta):\n",
    "    \"\"\"\n",
    "    Compute cost for linear regression. Computes the cost of using theta as the\n",
    "    parameter for linear regression to fit the data points in X and y.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The input dataset of shape (m x n+1), where m is the number of examples,\n",
    "        and n is the number of features. We assume a vector of one's already \n",
    "        appended to the features so we have n+1 columns.\n",
    "    \n",
    "    y : array_like\n",
    "        The values of the function at each data point. This is a vector of\n",
    "        shape (m, ).\n",
    "    \n",
    "    theta : array_like\n",
    "        The parameters for the regression function. This is a vector of \n",
    "        shape (n+1, ).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    J : float\n",
    "        The value of the regression cost function.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Compute the cost of a particular choice of theta. \n",
    "    You should set J to the cost.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize some useful values\n",
    "    m = y.size  # number of training examples\n",
    "    \n",
    "    # You need to return the following variables correctly\n",
    "    J = 0\n",
    "    \n",
    "    # ====================== YOUR CODE HERE =====================\n",
    "    #dot != dot product\n",
    "    #We dot all the cells in x and theta \n",
    "    h = np.dot(x,theta)\n",
    "    J = (1/(2*m))*np.sum(np.square(h-y))\n",
    "    \n",
    "    # ===========================================================\n",
    "  \n",
    "    return J\n",
    "#Why I was wrong the first time: When you do\n",
    "# J = (h-y[i]) * (h-y[i])\n",
    "# J += J\n",
    "#The dot product for each row can actually end up being 0*0 + 0*0\n",
    "# SO all you do is add 0 to itself when h is 0.\n",
    "#However, my code is hard coded for only theta.size == 2\n",
    "#Turn it into the general form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With theta = [0, 0] \n",
      "Cost computed = 32.07\n",
      "Expected cost value (approximately) 32.07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "J = computeCost(x, y, theta=np.array([0.0, 0.0]))\n",
    "print('With theta = [0, 0] \\nCost computed = %.2f' % J)\n",
    "print('Expected cost value (approximately) 32.07\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitting Solutions | Programming Exercise linear-regression\n",
      "\n",
      "Use token from last successful submission (canngo215@gmail.com)? (Y/n): Y\n",
      "                                  Part Name |     Score | Feedback\n",
      "                                  --------- |     ----- | --------\n",
      "                           Warm up exercise |  10 /  10 | Nice work!\n",
      "          Computing Cost (for one variable) |  40 /  40 | Nice work!\n",
      "        Gradient Descent (for one variable) |   0 /  50 | \n",
      "                      Feature Normalization |   0 /   0 | \n",
      "    Computing Cost (for multiple variables) |   0 /   0 | \n",
      "  Gradient Descent (for multiple variables) |   0 /   0 | \n",
      "                           Normal Equations |   0 /   0 | \n",
      "                                  --------------------------------\n",
      "                                            |  50 / 100 |  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "grader[2] = computeCost\n",
    "grader.grade()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X, y, theta, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    Performs gradient descent to learn `theta`. Updates theta by taking `num_iters`\n",
    "    gradient steps with learning rate `alpha`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The input dataset of shape (m x n+1).\n",
    "    \n",
    "    y : arra_like\n",
    "        Value at given features. A vector of shape (m, ).\n",
    "    \n",
    "    theta : array_like\n",
    "        Initial values for the linear regression parameters. \n",
    "        A vector of shape (n+1, ).\n",
    "    \n",
    "    alpha : float\n",
    "        The learning rate.\n",
    "    \n",
    "    num_iters : int\n",
    "        The number of iterations for gradient descent. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    theta : array_like\n",
    "        The learned linear regression parameters. A vector of shape (n+1, ).\n",
    "    \n",
    "    J_history : list\n",
    "        A python list for the values of the cost function after each iteration.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Peform a single gradient step on the parameter vector theta.\n",
    "\n",
    "    While debugging, it can be useful to print out the values of \n",
    "    the cost function (computeCost) and gradient here.\n",
    "    \"\"\"\n",
    "    # Initialize some useful values\n",
    "    m = y.shape[0]  # number of training examples\n",
    "    \n",
    "    # make a copy of theta, to avoid changing the original array, since numpy arrays\n",
    "    # are passed by reference to functions\n",
    "    theta = theta.copy()\n",
    "    \n",
    "    J_history = [] # Use a python list to save cost in every iteration\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # ==================== YOUR CODE HERE =================================\n",
    "        h = np.dot(X,theta)\n",
    "        theta =  theta - (alpha / m) * (h-y).dot(X)\n",
    "\n",
    "        # =====================================================================\n",
    "        \n",
    "        # save the cost J in every iteration\n",
    "        J_history.append(computeCost(X, y, theta))\n",
    "    \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize fitting parameters\n",
    "theta = np.zeros(2)\n",
    "\n",
    "# some gradient descent settings\n",
    "iterations = 1500\n",
    "alpha = 0.01\n",
    "\n",
    "theta, J_history = gradientDescent(x ,y, theta, alpha, iterations)\n",
    "print('Theta found by gradient descent: {:.4f}, {:.4f}'.format(*theta))\n",
    "print('Expected theta values (approximately): [-3.6303, 1.1664]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the linear fit\n",
    "plotData(X[:, 1], y)\n",
    "pyplot.plot(X[:, 1], np.dot(X, theta), '-')\n",
    "pyplot.legend(['Training data', 'Linear regression']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values for population sizes of 35,000 and 70,000\n",
    "predict1 = np.dot([1, 3.5], theta)\n",
    "print('For population = 35,000, we predict a profit of {:.2f}\\n'.format(predict1*10000))\n",
    "\n",
    "predict2 = np.dot([1, 7], theta)\n",
    "print('For population = 70,000, we predict a profit of {:.2f}\\n'.format(predict2*10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader[3] = gradientDescent\n",
    "grader.grade()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([1,2,3,4])\n",
    "x = np.array([[1,2],\n",
    "             [1,2],\n",
    "             [1,2],\n",
    "             [1,2]\n",
    "             ])\n",
    "print(a.dot(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
